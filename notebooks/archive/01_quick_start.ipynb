{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Genre Classification\n",
    "\n",
    "This notebook demonstrates how to use the refactored modules for quick experimentation.\n",
    "\n",
    "**What this notebook does:**\n",
    "- Loads and prepares data with a single function call\n",
    "- Trains a TF-IDF baseline model\n",
    "- Evaluates performance and visualizes results\n",
    "\n",
    "**All the complex code is now in `src/` modules!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import from our modules\n",
    "from src.data_loader import load_and_prepare_data\n",
    "from src.models import TFIDFModel\n",
    "from src.evaluate import evaluate_model, plot_confusion_matrix, plot_per_genre_metrics\n",
    "from src.utils import set_seed\n",
    "\n",
    "print(\"✓ Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "One line to load, clean, balance, and split the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# Load balanced dataset with 5,000 samples per genre\n",
    "X_train, X_test, y_train, y_test = load_and_prepare_data(\n",
    "    samples_per_genre=5000,  # Start small for quick testing\n",
    "    test_size=0.2,\n",
    "    use_cached=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Test samples: {len(X_test):,}\")\n",
    "print(f\"Genres: {sorted(y_train.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train TF-IDF Model\n",
    "\n",
    "Simple two-line training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train model\n",
    "model = TFIDFModel(\n",
    "    classifier_type='logistic',\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"✓ Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Comprehensive evaluation\n",
    "results = evaluate_model(y_test, y_pred, model_name=\"TF-IDF Baseline\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"Macro F1 Score: {results['macro_avg']['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    y_test, \n",
    "    y_pred,\n",
    "    title=\"TF-IDF Confusion Matrix\",\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-genre performance\n",
    "plot_per_genre_metrics(\n",
    "    results,\n",
    "    title=\"TF-IDF Per-Genre Performance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Top Features (Optional)\n",
    "\n",
    "See what words are most important for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get top features for each genre\n",
    "feature_importance = model.get_feature_importance(top_n=10)\n",
    "\n",
    "# Display as DataFrame for easy viewing\n",
    "for genre, features in feature_importance.items():\n",
    "    print(f\"\\n{genre.upper()}\")\n",
    "    df = pd.DataFrame(features, columns=['Feature', 'Importance'])\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**That's it!** Notice how clean this notebook is:\n",
    "- No data processing code (handled by `src/data_loader.py`)\n",
    "- No model implementation details (handled by `src/models.py`)\n",
    "- No evaluation code (handled by `src/evaluate.py`)\n",
    "\n",
    "**Next steps:**\n",
    "- Try `02_compare_models.ipynb` to compare TF-IDF, Word2Vec, and BERT\n",
    "- Or use command line: `python scripts/train.py --config experiments/configs/tfidf_config.yaml`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
